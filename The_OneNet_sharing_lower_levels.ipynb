{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "The OneNet - sharing lower levels",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOZPbSVeZPcFKJrO/ka3hFa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dd8bcaabc21145c1ba1944594af6f00d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fecf56ac51914527b0941a62c20a5fdc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2dbc18b47f724718a74403d54075e9eb",
              "IPY_MODEL_44bb4100a12c4f70a4af67e009a1de6d"
            ]
          }
        },
        "fecf56ac51914527b0941a62c20a5fdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2dbc18b47f724718a74403d54075e9eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f08703ad54be4027829515cd7a971bff",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_07eb571294114375b5818f8b32c8de3c"
          }
        },
        "44bb4100a12c4f70a4af67e009a1de6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3c6b1fe701054a78890e093516e5d232",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:17&lt;00:00, 55515677.80it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_74bb480762654701bff06ed72b160869"
          }
        },
        "f08703ad54be4027829515cd7a971bff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "07eb571294114375b5818f8b32c8de3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3c6b1fe701054a78890e093516e5d232": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "74bb480762654701bff06ed72b160869": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PyxAI/Data-Science-Notebooks/blob/master/The_OneNet_sharing_lower_levels.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MltUfww0oNgn",
        "colab_type": "text"
      },
      "source": [
        "In this experminet, I took two resnet18 pretrained networks and made them share the extracted features between them at lower layers of the network, rather than just at the classifier level.\n",
        "\n",
        "I've tried both Linear and Convolutional layers to be the ones shared between the networks.\n",
        "\n",
        "All of the experiments had a negative effect on the loss and accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e079am2gkawC",
        "colab_type": "code",
        "outputId": "ebda9a76-bbbb-4654-b23b-c911c8b1ec4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import os\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torchvision import models\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from google.colab import drive\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device('cuda')\n",
        "  dtype = torch.cuda.FloatTensor\n",
        "else:\n",
        "  device = torch.device('cpu')\n",
        "  dtype = torch.FloatTensor\n",
        "\n",
        "\n",
        "def validate(network, dset):\n",
        "  network.eval()\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    loss = 0\n",
        "    for x, y in dset:\n",
        "      x = x.to(device)\n",
        "      y = y.to(device)\n",
        "      output = network(x)\n",
        "      loss += loss_fn(output, y)\n",
        "      _, predicted = torch.max(output.data, 1)\n",
        "      total += y.size(0)\n",
        "      correct += (predicted == y).sum().item()\n",
        "    loss/= len(dset)\n",
        "    print (\"validation loss: {}\".format(loss))\n",
        "    print (\"accuracy here is: {}\".format(100 * correct / total))\n",
        "  return loss.detach().item()\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "!mkdir /content/weights\n",
        "!cp /content/gdrive/My\\ Drive/weights/resnet18_cifar.pt /content/weights/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DH3O0UaCascQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Squeezer(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Squeezer,self).__init__()\n",
        "  def forward(self, x):\n",
        "      return x.squeeze()\n",
        "\n",
        "class Identity(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Identity, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x\n",
        "\n",
        "def run_train(network):\n",
        "  loss_arr = []\n",
        "  try:\n",
        "    for epoch in range(epochs):\n",
        "      for iteration, (x, y) in enumerate(train):\n",
        "        network.train()\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        optim.zero_grad()\n",
        "        output = network(x)\n",
        "        loss = loss_fn(output, y)\n",
        "        loss.backward()\n",
        "        if (iteration % print_every == 0):\n",
        "          print (\"epoch: {}, iter:{}\".format(epoch, iteration))\n",
        "          loss_arr.append(validate(network, val))\n",
        "        optim.step()\n",
        "  except KeyboardInterrupt:\n",
        "    plt.plot(loss_arr)\n",
        "    plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ek3B9xihR_TM",
        "colab_type": "text"
      },
      "source": [
        "##Settings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hsy-v8ZSEM2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Training\n",
        "batch_size = 64\n",
        "lr = 2e-5\n",
        "epochs=200\n",
        "print_every = 100\n",
        "\n",
        "#Dataset\n",
        "cifar_root = '/content/data/cifar10'\n",
        "cifar_transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225]),\n",
        "    ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1Y5SbrM_Bub",
        "colab_type": "text"
      },
      "source": [
        "#Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_v0JKLTy3YwT",
        "colab_type": "code",
        "outputId": "a36a6980-8711-4819-f834-3a77a5ceeb36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119,
          "referenced_widgets": [
            "dd8bcaabc21145c1ba1944594af6f00d",
            "fecf56ac51914527b0941a62c20a5fdc",
            "2dbc18b47f724718a74403d54075e9eb",
            "44bb4100a12c4f70a4af67e009a1de6d",
            "f08703ad54be4027829515cd7a971bff",
            "07eb571294114375b5818f8b32c8de3c",
            "3c6b1fe701054a78890e093516e5d232",
            "74bb480762654701bff06ed72b160869"
          ]
        }
      },
      "source": [
        "#Take Cifar10\n",
        "cifar = datasets.CIFAR10(cifar_root, train=True, download=True, transform=cifar_transform)\n",
        "\n",
        "#split to train - val\n",
        "train_set, val_set = torch.utils.data.random_split(cifar, [int(len(cifar)*0.9), int(len(cifar)*0.1)])\n",
        "train = DataLoader(train_set, batch_size = batch_size, shuffle=True, num_workers = 4, drop_last =True)\n",
        "val = DataLoader(val_set, batch_size = batch_size, shuffle=True, num_workers = 4, drop_last =True)\n",
        "\n",
        "#test set\n",
        "cifar = datasets.CIFAR10(cifar_root, train=False, download=True, transform=cifar_transform)\n",
        "test = DataLoader(cifar, batch_size = batch_size, shuffle=True, num_workers = 4, drop_last =True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /content/data/cifar10/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dd8bcaabc21145c1ba1944594af6f00d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting /content/data/cifar10/cifar-10-python.tar.gz to /content/data/cifar10\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfL2R8Ao0s8J",
        "colab_type": "text"
      },
      "source": [
        "##Model setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzQIkKMnL_NL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "\n",
        "#Loading resnet with pretrained weights from CIFAR10\n",
        "resnet18A = models.resnet18(pretrained=False)\n",
        "resnet18A._modules['fc']= nn.Linear(512, 10) #To make it CIFARable\n",
        "resnet18A.load_state_dict(torch.load('/content/gdrive/My Drive/weights/ready_resnet18_cifar.pt', map_location=torch.device(device)))\n",
        "resnet18A.fc = Identity()\n",
        "\n",
        "#Resnet with ImageNet\n",
        "resnet18B = models.resnet18(pretrained=True)\n",
        "resnet18B.fc = Identity()\n",
        "\n",
        "resnet18A.to(device)\n",
        "resnet18B.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_1hWCos04nf",
        "colab_type": "text"
      },
      "source": [
        "Shutting down grad on everything but FC layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThRze7i3azaG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Shutting down grad on everything but FC layer\n",
        "for param in resnet18A.named_parameters():\n",
        "  if not any(['body' in param[0]]):\n",
        "    param[1].requires_grad=False\n",
        "\n",
        "#Shutting down grad on everything but FC layer\n",
        "for param in resnet18B.named_parameters():\n",
        "  if not any(['body' in param[0]]):\n",
        "    param[1].requires_grad=False\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Pn9ccWfMp02",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Separation the different steps \n",
        "\n",
        "t0 = nn.Sequential(\n",
        "    resnet18A.conv1,\n",
        "    resnet18A.bn1,\n",
        "    resnet18A.relu,\n",
        "    resnet18A.maxpool\n",
        ")\n",
        "\n",
        "t1 = resnet18A.layer1\n",
        "t2 = resnet18A.layer2\n",
        "t3 = resnet18A.layer3\n",
        "t4 = resnet18A.layer4\n",
        "head = nn.Sequential(\n",
        "    resnet18A.avgpool,\n",
        ")\n",
        "\n",
        "r0 = nn.Sequential(\n",
        "    resnet18B.conv1,\n",
        "    resnet18B.bn1,\n",
        "    resnet18B.relu,\n",
        "    resnet18B.maxpool\n",
        ")\n",
        "\n",
        "r1 = resnet18B.layer1\n",
        "r2 = resnet18B.layer2\n",
        "r3 = resnet18B.layer3\n",
        "r4 = resnet18B.layer4\n",
        "rhead = nn.Sequential(\n",
        "    resnet18B.avgpool,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nP-nlTiVPzfG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FriendNetConv(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(FriendNetConv, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Sequential(\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Conv2d(512,256, kernel_size=(1,1)),\n",
        "    )\n",
        "\n",
        "    self.body = nn.Sequential(\n",
        "            nn.LeakyReLU(),\n",
        "            Squeezer(),\n",
        "            nn.Linear(512*2, 10),\n",
        "        )\n",
        "  # We run forward on each layer of each network seperatley.\n",
        "  def forward(self, x):\n",
        "    x11 = t0(x)\n",
        "    x12 = r0(x)\n",
        "    x21 = t1(x11)\n",
        "    x22 = r1(x12)\n",
        "    x31 = t2(x21)\n",
        "    x32 = r2(x22)\n",
        "    x41 = t3(x31)\n",
        "    x42 = r3(x32)\n",
        "    # Concatenating and running conv layer\n",
        "    x1 = torch.cat((x41, x42),dim=1)\n",
        "    x1 = self.conv1(x1)\n",
        "    # Feeding back to the original structure\n",
        "    x51 = t4(x1)\n",
        "    x52 = r4(x1)\n",
        "    x61 = head(x51)\n",
        "    x62 = rhead(x52)\n",
        "    x6 = torch.cat((x61, x62), dim=1)\n",
        "    x = self.body(x6)\n",
        "    return x\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6bMjBx1X5FZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FriendNetLinear(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(FriendNetLinear, self).__init__()\n",
        "    \n",
        "    self.lin1 = nn.Sequential(\n",
        "        nn.LeakyReLU(),\n",
        "        nn.Linear(2048, 256, bias=True),\n",
        "        #nn.LeakyReLU(),\n",
        "    )\n",
        "    \n",
        "    self.body = nn.Sequential(\n",
        "            nn.LeakyReLU(),\n",
        "            Squeezer(),\n",
        "            nn.Linear(512*2, 10),\n",
        "        )\n",
        "    self.bn1 = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x11 = t0(x)\n",
        "    x12 = r0(x)\n",
        "    x21 = t1(x11)\n",
        "    x22 = r1(x12)\n",
        "    x31 = t2(x21)\n",
        "    x32 = r2(x22)\n",
        "    x41 = t3(x31)\n",
        "    x42 = r3(x32)\n",
        "    x1 = torch.cat((x41, x42),dim=1)\n",
        "    x1 = x1.view(batch_size,-1,1,1).squeeze() # to shape: (batch_size, 2048)\n",
        "    x1 = self.lin1(x1)\n",
        "    x1 = x1.view(batch_size,-1,1,1) # to shape: (batch_size, 256,1,1)\n",
        "    x1 = self.bn1(x1)\n",
        "    x51 = t4(x1)\n",
        "    x52 = r4(x1)\n",
        "    x61 = head(x51)\n",
        "    x62 = rhead(x52)\n",
        "    x6 = torch.cat((x61, x62), dim=1)\n",
        "    x = self.body(x6)\n",
        "    return x\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4PD4hkmaXRV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "friend = FriendNetLinear()\n",
        "\n",
        "optim = torch.optim.Adam(friend.parameters(), lr=lr)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "friend.to(device)\n",
        "\n",
        "run_train(friend)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3MTLle92JMW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "friend = FriendNetConv()\n",
        "\n",
        "optim = torch.optim.Adam(friend.parameters(), lr=lr)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "friend.to(device)\n",
        "run_train(friend)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}